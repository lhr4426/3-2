{"cells":[{"cell_type":"markdown","metadata":{"id":"2WRoeHk2BRLa"},"source":["# 수강생분의 이름, 학번을 반영해주세요."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1699613714268,"user":{"displayName":"이혜림컴퓨터공학과","userId":"12232423623052772806"},"user_tz":-540},"id":"p6lZMos0BRLb","outputId":"a61bdc11-4b60-492e-a1e4-463015a51f24"},"outputs":[{"output_type":"stream","name":"stdout","text":["20211924 이혜림\n"]}],"source":["id = '20211924'\n","name = '이혜림'\n","print(id, name)"]},{"cell_type":"markdown","metadata":{"id":"oFSdnGtSfPy2"},"source":["코랩 메뉴 -> 수정 -> 노트 설정 -> 하드웨어 가속기 GPU 권장(행렬 연산이 많기 때문)"]},{"cell_type":"markdown","metadata":{"id":"mmfPv3pvSyzW"},"source":["구글 드라이브 연동"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15030,"status":"ok","timestamp":1699613729293,"user":{"displayName":"이혜림컴퓨터공학과","userId":"12232423623052772806"},"user_tz":-540},"id":"2Xgv13b9SylY","outputId":"04f221e1-1ad4-498d-9f77-77967760c037"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/gdrive')"]},{"cell_type":"markdown","metadata":{"id":"wjGCZX3rTDzf"},"source":["폴더 경로 설정"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1699613729294,"user":{"displayName":"이혜림컴퓨터공학과","userId":"12232423623052772806"},"user_tz":-540},"id":"xPQ6ZqgNTEUp"},"outputs":[],"source":["workspace_path = '/gdrive/My Drive/Colab Notebooks/AI/AI_week10'"]},{"cell_type":"markdown","metadata":{"id":"rb7H5Sj7unoc"},"source":["파이썬 패키지 로드"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1699613729294,"user":{"displayName":"이혜림컴퓨터공학과","userId":"12232423623052772806"},"user_tz":-540},"id":"5PqsCDfWurAU"},"outputs":[],"source":["import os\n","import sys\n","sys.path.append(os.path.join(workspace_path, 'PyTorch_CIFAR10-master'))  # PyTorch_CIFAR10 반영"]},{"cell_type":"markdown","metadata":{"id":"A24rzsRaNf4G"},"source":["필요 패키지 로드"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5247,"status":"ok","timestamp":1699613734537,"user":{"displayName":"이혜림컴퓨터공학과","userId":"12232423623052772806"},"user_tz":-540},"id":"f35aBUozTot0"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","import os\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"c-stOtMGg680"},"source":["결과 재현을 위한 설정 (GPU 연산방식에 따라 실험결과가 약간 다를 수 있음)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1699613734537,"user":{"displayName":"이혜림컴퓨터공학과","userId":"12232423623052772806"},"user_tz":-540},"id":"BSMYLVv-g8a_"},"outputs":[],"source":["\n","seed = 719\n","random.seed(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"]},{"cell_type":"markdown","metadata":{"id":"8H-POAtgNiXH"},"source":["합성곱 신경망(CNN) 정의"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1699613734538,"user":{"displayName":"이혜림컴퓨터공학과","userId":"12232423623052772806"},"user_tz":-540},"id":"73ayL6tKTtf1","outputId":"76dd7816-d77a-4be8-b073-42a81d172b8f"},"outputs":[{"output_type":"stream","name":"stdout","text":["init model done\n"]}],"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.main = nn.Sequential(\n","            nn.Conv2d(in_channels=3, out_channels=10, kernel_size=3,\n","                      stride=1, padding=1, bias=False),  # 3x32x32 -> 10x32x32\n","            nn.BatchNorm2d(10),  # 배치 정규화\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3,\n","                      stride=1, padding=1, bias=False),  # 10x32x32 -> 20x32x32\n","            nn.BatchNorm2d(20),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2),  # 20x32x32 -> 20x16x16 (특징 압축)\n","            nn.Conv2d(in_channels=20, out_channels=40, kernel_size=3,\n","                      stride=1, padding=1, bias=False),  # 20x16x16 -> 40x16x16\n","            nn.BatchNorm2d(40),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2),\n","            nn.Conv2d(in_channels=40, out_channels=80, kernel_size=3,\n","                      stride=1, padding=1, bias=False),  # 40x8x8 -> 80x8x8\n","            nn.BatchNorm2d(80),\n","            nn.AdaptiveAvgPool2d(1)  # 80x8x8 -> 80x1x1 (채널 별 평균값 계산)\n","        )\n","        self.fc = nn.Linear(80, 10)  # 출력값의 차원은 판별할 클래스 수인 10으로 설정 (CIFAR-10 10종 판별 문제)\n","\n","    def forward(self, x):\n","        x = x.float()\n","        x = x.view(-1, 3, 32, 32)  # view 함수로 tensor 형태 변경: [batch크기, 3, 32, 32]\n","        x = self.main(x)  # CNN 모델 feed-forward\n","        x = x.view(-1, 80)  # view 함수로 형태 변경: [batch크기, 80]\n","        x = self.fc(x)  # 마지막 레이어에는 활성화 함수 사용하지 않음\n","        return x\n","\n","print(\"init model done\")"]},{"cell_type":"markdown","metadata":{"id":"8ubIJ-THNmsg"},"source":["모델 학습을 위한 하이퍼파라미터 셋팅"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1699613734538,"user":{"displayName":"이혜림컴퓨터공학과","userId":"12232423623052772806"},"user_tz":-540},"id":"NIFF2C4VUsu2","outputId":"c1893681-1e3d-43bb-f31a-af163799accd"},"outputs":[{"output_type":"stream","name":"stdout","text":["set vars and device done\n"]}],"source":["batch_size = 64  # 학습 배치 크기\n","test_batch_size = 1000  # 테스트 배치 크기 (학습 과정을 제외하므로 더 큰 배치 사용 가능)\n","max_epochs = 10  # 학습 데이터셋 총 훈련 횟수\n","lr = 0.01  # 학습률\n","momentum = 0.5  # SGD에 사용할 모멘텀 설정 (파라미터 업데이트 시 관성 효과 사용)\n","log_interval = 200  # interval 때마다 로그 남김\n","\n","use_cuda = torch.cuda.is_available()  # GPU cuda 사용 여부 확인\n","\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")  # GPU cuda 사용하거나 없다면 CPU 사용\n","\n","kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}  # num_workers: data loading할 프로세스 수, pin_memory: 고정된 메모리 영역 사용\n","\n","print(\"set vars and device done\")"]},{"cell_type":"markdown","metadata":{"id":"yobSwgppPEPB"},"source":["데이터 로더 정의 (학습용, 테스트용 따로 정의)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7326,"status":"ok","timestamp":1699613741858,"user":{"displayName":"이혜림컴퓨터공학과","userId":"12232423623052772806"},"user_tz":-540},"id":"L_qvQSstUttY","outputId":"32b26675-8605-460a-a3c4-cf043cbc90f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["train_transform = transforms.Compose([\n","                                      ## augmentation 추가 가능\n","                 transforms.ToTensor(),  # numpy array -> tensor 변환\n","                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])  # 입력값 정규화 (일반적으로는 학습 데이터셋의 평균, 표준편차 사용)\n","\n","val_transform = transforms.Compose([\n","                 transforms.ToTensor(),  # numpy array -> tensor 변환\n","                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])  # 입력값 정규화 (일반적으로는 학습 데이터셋의 평균, 표준편차 사용)\n","\n","# CIFAR-10 link: https://www.cs.toronto.edu/~kriz/cifar.html\n","# 학습용 데이터 로더 (CIFAR-10 학습 데이터셋 사용)\n","train_loader = torch.utils.data.DataLoader(\n","  datasets.CIFAR10(os.path.join(workspace_path, 'data'), train=True, download=True,\n","                   transform=train_transform),\n","    batch_size = batch_size, shuffle=True, drop_last=True, **kwargs)  # drop_last: 마지막 미니배치 크기가 batch_size 이하면 drop\n","\n","# 테스트용 데이터 로더 (CIFAR-10 테스트 데이터셋 사용)\n","test_loader = torch.utils.data.DataLoader(\n","        datasets.CIFAR10(os.path.join(workspace_path, 'data'), train=False, download=True,\n","                         transform=val_transform),\n","    batch_size=test_batch_size, shuffle=False, **kwargs)"]},{"cell_type":"markdown","metadata":{"id":"772mQzMoPf6E"},"source":["모델, 최적화 알고리즘, 손실 함수 정의"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5555,"status":"ok","timestamp":1699613747408,"user":{"displayName":"이혜림컴퓨터공학과","userId":"12232423623052772806"},"user_tz":-540},"id":"i7g8ejQCWaZl"},"outputs":[],"source":["model = Net().to(device)  # 모델 정의\n","optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)  # 최적화 알고리즘 정의 (SGD 사용)\n","criterion = nn.CrossEntropyLoss()  # 손실 함수 정의 (CrossEntropy 사용)"]},{"cell_type":"markdown","metadata":{"id":"oEkVPA1JXpmX"},"source":["AverageMeter 정의"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1699613747409,"user":{"displayName":"이혜림컴퓨터공학과","userId":"12232423623052772806"},"user_tz":-540},"id":"UMjKwVdbXs6f"},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"]},{"cell_type":"markdown","metadata":{"id":"UEWH5E_yPr5x"},"source":["학습, 테스트용 함수 정의"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1699613747409,"user":{"displayName":"이혜림컴퓨터공학과","userId":"12232423623052772806"},"user_tz":-540},"id":"6DiSca1AVKJZ"},"outputs":[],"source":["def train(log_interval, model, device, train_loader, optimizer, epoch):\n","    model.train()  # 모델 학습 모드 설정\n","    summary_loss = AverageMeter()  # 학습 손실값 기록 초기화\n","    summary_acc = AverageMeter() # 학습 정확도 기록 초기화\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)  # 현재 미니 배치의 데이터, 정답 불러옴\n","        optimizer.zero_grad()  # gradient 0으로 초기화\n","        output = model(data)  # 모델에 입력값 feed-forward\n","        loss = criterion(output, target)  # 예측값(클래스 별 score)과 정답간의 손실값 계산\n","        loss.backward()  # 손실값 역전파 (각 계층에서 gradient 계산, pytorch는 autograd로 gradient 자동 계산)\n","        optimizer.step()  # 모델의 파라미터 업데이트 (gradient 이용하여 파라미터 업데이트)\n","        summary_loss.update(loss.detach().item())  # 손실값 기록\n","        pred = output.argmax(dim=1, keepdim=True)  # 예측값 중에서 최고 score를 달성한 클래스 선발\n","        correct = pred.eq(target.view_as(pred)).sum().item()  # 정답과 예측 클래스가 일치한 개수\n","        summary_acc.update(correct / data.size(0))  # 정확도 기록\n","        if batch_idx % log_interval == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tAverage loss: {:.6f}, Accuracy: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), summary_loss.avg, summary_acc.avg))\n","\n","    return summary_loss.avg, summary_acc.avg\n","\n","def test(log_interval, model, device, test_loader):\n","    model.eval()  # 모델 검증 모드 설정 (inference mode)\n","    summary_loss = AverageMeter()  # 테스트 손실값 기록 초기화\n","    summary_acc = AverageMeter() # 테스트 정확도 기록 초기화\n","    with torch.no_grad():  # 검증 모드이므로 gradient 계산안함\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)  # 현재 미니 배치의 데이터, 정답 불러옴\n","            output = model(data)  # 모델에 입력값 feed-forward\n","            loss = criterion(output, target)  # 예측값(클래스 별 score)과 정답간의 손실값 계산\n","            summary_loss.update(loss.detach().item())  # 손실값 기록\n","            pred = output.argmax(dim=1, keepdim=True)  # 예측값 중에서 최고 score를 달성한 클래스 선발\n","            correct = pred.eq(target.view_as(pred)).sum().item()  # 정답과 예측 클래스가 일치한 개수\n","            summary_acc.update(correct / data.size(0))  # 정확도 기록\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {:.6f}\\n'.format\n","          (summary_loss.avg, summary_acc.avg))  # 정답을 맞춘 개수 / 테스트셋 샘플 수 -> Accuracy\n","\n","    return summary_loss.avg, summary_acc.avg"]},{"cell_type":"markdown","metadata":{"id":"g2T5yl2ETeKL"},"source":["학습, 테스트, 모델 저장 수행"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":208682,"status":"ok","timestamp":1699613956088,"user":{"displayName":"이혜림컴퓨터공학과","userId":"12232423623052772806"},"user_tz":-540},"id":"830vHfcPWqVE","outputId":"7aac13d6-e387-4965-a0f4-83642c82b071"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 [0/50000 (0%)]\tAverage loss: 2.324592, Accuracy: 0.109375\n","Train Epoch: 1 [12800/50000 (26%)]\tAverage loss: 1.851650, Accuracy: 0.318719\n","Train Epoch: 1 [25600/50000 (51%)]\tAverage loss: 1.735568, Accuracy: 0.365648\n","Train Epoch: 1 [38400/50000 (77%)]\tAverage loss: 1.673766, Accuracy: 0.391041\n","\n","Test set: Average loss: 1.5657, Accuracy: 0.423600\n","\n","# save model: cifar10_cnn_model_best_acc_1-epoch.pt\n","\n","Train Epoch: 2 [0/50000 (0%)]\tAverage loss: 1.372632, Accuracy: 0.562500\n","Train Epoch: 2 [12800/50000 (26%)]\tAverage loss: 1.424659, Accuracy: 0.488184\n","Train Epoch: 2 [25600/50000 (51%)]\tAverage loss: 1.408765, Accuracy: 0.493454\n","Train Epoch: 2 [38400/50000 (77%)]\tAverage loss: 1.392645, Accuracy: 0.502574\n","\n","Test set: Average loss: 1.3420, Accuracy: 0.511600\n","\n","# save model: cifar10_cnn_model_best_acc_2-epoch.pt\n","\n","Train Epoch: 3 [0/50000 (0%)]\tAverage loss: 1.165542, Accuracy: 0.593750\n","Train Epoch: 3 [12800/50000 (26%)]\tAverage loss: 1.283224, Accuracy: 0.547886\n","Train Epoch: 3 [25600/50000 (51%)]\tAverage loss: 1.277864, Accuracy: 0.548706\n","Train Epoch: 3 [38400/50000 (77%)]\tAverage loss: 1.267590, Accuracy: 0.552699\n","\n","Test set: Average loss: 1.2621, Accuracy: 0.552700\n","\n","# save model: cifar10_cnn_model_best_acc_3-epoch.pt\n","\n","Train Epoch: 4 [0/50000 (0%)]\tAverage loss: 1.202062, Accuracy: 0.546875\n","Train Epoch: 4 [12800/50000 (26%)]\tAverage loss: 1.195079, Accuracy: 0.575715\n","Train Epoch: 4 [25600/50000 (51%)]\tAverage loss: 1.200434, Accuracy: 0.572592\n","Train Epoch: 4 [38400/50000 (77%)]\tAverage loss: 1.187154, Accuracy: 0.578307\n","\n","Test set: Average loss: 1.4877, Accuracy: 0.510400\n","\n","Train Epoch: 5 [0/50000 (0%)]\tAverage loss: 1.114627, Accuracy: 0.593750\n","Train Epoch: 5 [12800/50000 (26%)]\tAverage loss: 1.120279, Accuracy: 0.603467\n","Train Epoch: 5 [25600/50000 (51%)]\tAverage loss: 1.116052, Accuracy: 0.605440\n","Train Epoch: 5 [38400/50000 (77%)]\tAverage loss: 1.111605, Accuracy: 0.606411\n","\n","Test set: Average loss: 1.0887, Accuracy: 0.612500\n","\n","# save model: cifar10_cnn_model_best_acc_5-epoch.pt\n","\n","Train Epoch: 6 [0/50000 (0%)]\tAverage loss: 0.910922, Accuracy: 0.640625\n","Train Epoch: 6 [12800/50000 (26%)]\tAverage loss: 1.061843, Accuracy: 0.622279\n","Train Epoch: 6 [25600/50000 (51%)]\tAverage loss: 1.057234, Accuracy: 0.624688\n","Train Epoch: 6 [38400/50000 (77%)]\tAverage loss: 1.059466, Accuracy: 0.624896\n","\n","Test set: Average loss: 1.2802, Accuracy: 0.551700\n","\n","Train Epoch: 7 [0/50000 (0%)]\tAverage loss: 1.028156, Accuracy: 0.656250\n","Train Epoch: 7 [12800/50000 (26%)]\tAverage loss: 1.016302, Accuracy: 0.635883\n","Train Epoch: 7 [25600/50000 (51%)]\tAverage loss: 1.025353, Accuracy: 0.636534\n","Train Epoch: 7 [38400/50000 (77%)]\tAverage loss: 1.016170, Accuracy: 0.642471\n","\n","Test set: Average loss: 1.0646, Accuracy: 0.618600\n","\n","# save model: cifar10_cnn_model_best_acc_7-epoch.pt\n","\n","Train Epoch: 8 [0/50000 (0%)]\tAverage loss: 0.877894, Accuracy: 0.671875\n","Train Epoch: 8 [12800/50000 (26%)]\tAverage loss: 0.989873, Accuracy: 0.649487\n","Train Epoch: 8 [25600/50000 (51%)]\tAverage loss: 0.978129, Accuracy: 0.655042\n","Train Epoch: 8 [38400/50000 (77%)]\tAverage loss: 0.980351, Accuracy: 0.653182\n","\n","Test set: Average loss: 1.4322, Accuracy: 0.534600\n","\n","Train Epoch: 9 [0/50000 (0%)]\tAverage loss: 1.058963, Accuracy: 0.625000\n","Train Epoch: 9 [12800/50000 (26%)]\tAverage loss: 0.941873, Accuracy: 0.673818\n","Train Epoch: 9 [25600/50000 (51%)]\tAverage loss: 0.949132, Accuracy: 0.668563\n","Train Epoch: 9 [38400/50000 (77%)]\tAverage loss: 0.950926, Accuracy: 0.667299\n","\n","Test set: Average loss: 1.1030, Accuracy: 0.616300\n","\n","Train Epoch: 10 [0/50000 (0%)]\tAverage loss: 0.872445, Accuracy: 0.718750\n","Train Epoch: 10 [12800/50000 (26%)]\tAverage loss: 0.922141, Accuracy: 0.674829\n","Train Epoch: 10 [25600/50000 (51%)]\tAverage loss: 0.926570, Accuracy: 0.672343\n","Train Epoch: 10 [38400/50000 (77%)]\tAverage loss: 0.927685, Accuracy: 0.674527\n","\n","Test set: Average loss: 1.1976, Accuracy: 0.607700\n","\n","\n","\n","# Best accuracy model(61.86%): cifar10_cnn_model_best_acc_7-epoch.pt\n","\n"]}],"source":["best_acc = 0\n","best_epoch = 0\n","for epoch in range(1, max_epochs+1):\n","    train_loss, train_acc = train(log_interval, model, device, train_loader, optimizer, epoch)\n","    test_loss, test_acc = test(log_interval, model, device, test_loader)\n","\n","    # 테스트에서 best accuracy 달성하면 모델 저장\n","    if test_acc > best_acc:\n","        best_acc = test_acc\n","        best_epoch = epoch\n","        torch.save(model, os.path.join(workspace_path, f'cifar10_cnn_model_best_acc_{best_epoch}-epoch.pt'))\n","        print(f'# save model: cifar10_cnn_model_best_acc_{best_epoch}-epoch.pt\\n')\n","\n","print(f'\\n\\n# Best accuracy model({best_acc * 100:.2f}%): cifar10_cnn_model_best_acc_{best_epoch}-epoch.pt\\n')"]},{"cell_type":"markdown","metadata":{"id":"nRP04ogeUJkm"},"source":["# 실습과제"]},{"cell_type":"markdown","metadata":{"id":"_pEKYSYIAz9F"},"source":["## baseline 모델 성능: 62.70%\n","- GPU 연산방식에 따라 실험결과가 약간 다를 수 있음\n","- 본인 코드의 baseline 성능을 기준으로 잡을 것"]},{"cell_type":"markdown","metadata":{"id":"9Jlw_NQJArdR"},"source":["## baseline보다 성능 높이기"]},{"cell_type":"markdown","metadata":{"id":"F6T4aldug3ny"},"source":["### 1) baseline + 데이터증대 + 하이퍼파라미터 수정하여 성능 높이기 (다른 augmentation 패키지도 사용 가능)\n","torchvision augmentation 링크: https://pytorch.org/vision/stable/transforms.html"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":224658,"status":"ok","timestamp":1699614180718,"user":{"displayName":"이혜림컴퓨터공학과","userId":"12232423623052772806"},"user_tz":-540},"id":"iJvh9KjKv99R","outputId":"03f107e1-2bbf-4e80-bbab-18654f19e3ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["set vars and device done\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Train Epoch: 1 [0/50000 (0%)]\tAverage loss: 2.271701, Accuracy: 0.156250\n","Train Epoch: 1 [12800/50000 (26%)]\tAverage loss: 1.851292, Accuracy: 0.324549\n","Train Epoch: 1 [25600/50000 (51%)]\tAverage loss: 1.751267, Accuracy: 0.361401\n","Train Epoch: 1 [38400/50000 (77%)]\tAverage loss: 1.682009, Accuracy: 0.389481\n","\n","Test set: Average loss: 1.5379, Accuracy: 0.435100\n","\n","# save model: cifar10_cnn_model_best_acc_1-epoch.pt\n","\n","Train Epoch: 2 [0/50000 (0%)]\tAverage loss: 1.303965, Accuracy: 0.593750\n","Train Epoch: 2 [12800/50000 (26%)]\tAverage loss: 1.414349, Accuracy: 0.492926\n","Train Epoch: 2 [25600/50000 (51%)]\tAverage loss: 1.403350, Accuracy: 0.498792\n","Train Epoch: 2 [38400/50000 (77%)]\tAverage loss: 1.387083, Accuracy: 0.507046\n","\n","Test set: Average loss: 1.4911, Accuracy: 0.468100\n","\n","# save model: cifar10_cnn_model_best_acc_2-epoch.pt\n","\n","Train Epoch: 3 [0/50000 (0%)]\tAverage loss: 1.460679, Accuracy: 0.531250\n","Train Epoch: 3 [12800/50000 (26%)]\tAverage loss: 1.289654, Accuracy: 0.544698\n","Train Epoch: 3 [25600/50000 (51%)]\tAverage loss: 1.274374, Accuracy: 0.550538\n","Train Epoch: 3 [38400/50000 (77%)]\tAverage loss: 1.259600, Accuracy: 0.555012\n","\n","Test set: Average loss: 1.3748, Accuracy: 0.504400\n","\n","# save model: cifar10_cnn_model_best_acc_3-epoch.pt\n","\n","Train Epoch: 4 [0/50000 (0%)]\tAverage loss: 1.073024, Accuracy: 0.656250\n","Train Epoch: 4 [12800/50000 (26%)]\tAverage loss: 1.185406, Accuracy: 0.581856\n","Train Epoch: 4 [25600/50000 (51%)]\tAverage loss: 1.175860, Accuracy: 0.586931\n","Train Epoch: 4 [38400/50000 (77%)]\tAverage loss: 1.171367, Accuracy: 0.588602\n","\n","Test set: Average loss: 1.2196, Accuracy: 0.576500\n","\n","# save model: cifar10_cnn_model_best_acc_4-epoch.pt\n","\n","Train Epoch: 5 [0/50000 (0%)]\tAverage loss: 1.014743, Accuracy: 0.671875\n","Train Epoch: 5 [12800/50000 (26%)]\tAverage loss: 1.112064, Accuracy: 0.607198\n","Train Epoch: 5 [25600/50000 (51%)]\tAverage loss: 1.109446, Accuracy: 0.604972\n","Train Epoch: 5 [38400/50000 (77%)]\tAverage loss: 1.110459, Accuracy: 0.605553\n","\n","Test set: Average loss: 1.1762, Accuracy: 0.572600\n","\n","Train Epoch: 6 [0/50000 (0%)]\tAverage loss: 1.049353, Accuracy: 0.625000\n","Train Epoch: 6 [12800/50000 (26%)]\tAverage loss: 1.057346, Accuracy: 0.625466\n","Train Epoch: 6 [25600/50000 (51%)]\tAverage loss: 1.066275, Accuracy: 0.623831\n","Train Epoch: 6 [38400/50000 (77%)]\tAverage loss: 1.062047, Accuracy: 0.624246\n","\n","Test set: Average loss: 1.3492, Accuracy: 0.531900\n","\n","Train Epoch: 7 [0/50000 (0%)]\tAverage loss: 0.899116, Accuracy: 0.656250\n","Train Epoch: 7 [12800/50000 (26%)]\tAverage loss: 1.029444, Accuracy: 0.634328\n","Train Epoch: 7 [25600/50000 (51%)]\tAverage loss: 1.022629, Accuracy: 0.640002\n","Train Epoch: 7 [38400/50000 (77%)]\tAverage loss: 1.026457, Accuracy: 0.637349\n","\n","Test set: Average loss: 1.0759, Accuracy: 0.616300\n","\n","# save model: cifar10_cnn_model_best_acc_7-epoch.pt\n","\n","Train Epoch: 8 [0/50000 (0%)]\tAverage loss: 0.939359, Accuracy: 0.703125\n","Train Epoch: 8 [12800/50000 (26%)]\tAverage loss: 0.986587, Accuracy: 0.652363\n","Train Epoch: 8 [25600/50000 (51%)]\tAverage loss: 0.988081, Accuracy: 0.650990\n","Train Epoch: 8 [38400/50000 (77%)]\tAverage loss: 0.991444, Accuracy: 0.650348\n","\n","Test set: Average loss: 1.0690, Accuracy: 0.625200\n","\n","# save model: cifar10_cnn_model_best_acc_8-epoch.pt\n","\n","Train Epoch: 9 [0/50000 (0%)]\tAverage loss: 1.009606, Accuracy: 0.609375\n","Train Epoch: 9 [12800/50000 (26%)]\tAverage loss: 0.957578, Accuracy: 0.657649\n","Train Epoch: 9 [25600/50000 (51%)]\tAverage loss: 0.963471, Accuracy: 0.657458\n","Train Epoch: 9 [38400/50000 (77%)]\tAverage loss: 0.967390, Accuracy: 0.655782\n","\n","Test set: Average loss: 1.0452, Accuracy: 0.638000\n","\n","# save model: cifar10_cnn_model_best_acc_9-epoch.pt\n","\n","Train Epoch: 10 [0/50000 (0%)]\tAverage loss: 0.896836, Accuracy: 0.703125\n","Train Epoch: 10 [12800/50000 (26%)]\tAverage loss: 0.949804, Accuracy: 0.663013\n","Train Epoch: 10 [25600/50000 (51%)]\tAverage loss: 0.946168, Accuracy: 0.665952\n","Train Epoch: 10 [38400/50000 (77%)]\tAverage loss: 0.944332, Accuracy: 0.667663\n","\n","Test set: Average loss: 0.9959, Accuracy: 0.650800\n","\n","# save model: cifar10_cnn_model_best_acc_10-epoch.pt\n","\n","\n","\n","# Best accuracy model(65.08%): cifar10_cnn_model_best_acc_10-epoch.pt\n","\n"]}],"source":["batch_size = 64  # 학습 배치 크기\n","test_batch_size = 1000  # 테스트 배치 크기 (학습 과정을 제외하므로 더 큰 배치 사용 가능)\n","max_epochs = 10  # 학습 데이터셋 총 훈련 횟수\n","lr = 0.01  # 학습률\n","momentum = 0.5  # SGD에 사용할 모멘텀 설정 (파라미터 업데이트 시 관성 효과 사용)\n","log_interval = 200  # interval 때마다 로그 남김\n","\n","use_cuda = torch.cuda.is_available()  # GPU cuda 사용 여부 확인\n","\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")  # GPU cuda 사용하거나 없다면 CPU 사용\n","\n","kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}  # num_workers: data loading할 프로세스 수, pin_memory: 고정된 메모리 영역 사용\n","\n","print(\"set vars and device done\")\n","\n","\n","train_transform = transforms.Compose([\n","                ## --------------- 추가 -----------------\n","                transforms.RandomHorizontalFlip(0.7), # 랜덤으로 수평 반전 (70% 확률로)\n","                ## --------------- 추가 -----------------\n","                                      ## augmentation 추가 가능\n","                 transforms.ToTensor(),  # numpy array -> tensor 변환\n","                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])  # 입력값 정규화 (일반적으로는 학습 데이터셋의 평균, 표준편차 사용)\n","\n","val_transform = transforms.Compose([\n","                 transforms.ToTensor(),  # numpy array -> tensor 변환\n","                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])  # 입력값 정규화 (일반적으로는 학습 데이터셋의 평균, 표준편차 사용)\n","\n","train_loader = None\n","test_loader = None\n","\n","# CIFAR-10 link: https://www.cs.toronto.edu/~kriz/cifar.html\n","# 학습용 데이터 로더 (CIFAR-10 학습 데이터셋 사용)\n","train_loader = torch.utils.data.DataLoader(\n","  datasets.CIFAR10(os.path.join(workspace_path, 'data'), train=True, download=True,\n","                   transform=train_transform),\n","    batch_size = batch_size, shuffle=True, drop_last=True, **kwargs)  # drop_last: 마지막 미니배치 크기가 batch_size 이하면 drop\n","\n","# 테스트용 데이터 로더 (CIFAR-10 테스트 데이터셋 사용)\n","test_loader = torch.utils.data.DataLoader(\n","        datasets.CIFAR10(os.path.join(workspace_path, 'data'), train=False, download=True,\n","                         transform=val_transform),\n","    batch_size=test_batch_size, shuffle=False, **kwargs)\n","\n","model = Net().to(device)  # 모델 정의\n","optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)  # 최적화 알고리즘 정의 (SGD 사용)\n","criterion = nn.CrossEntropyLoss()  # 손실 함수 정의 (CrossEntropy 사용)\n","\n","best_acc = 0\n","best_epoch = 0\n","for epoch in range(1, max_epochs+1):\n","    train_loss, train_acc = train(log_interval, model, device, train_loader, optimizer, epoch)\n","    test_loss, test_acc = test(log_interval, model, device, test_loader)\n","\n","    # 테스트에서 best accuracy 달성하면 모델 저장\n","    if test_acc > best_acc:\n","        best_acc = test_acc\n","        best_epoch = epoch\n","        torch.save(model, os.path.join(workspace_path, f'cifar10_cnn_model_best_acc_{best_epoch}-epoch.pt'))\n","        print(f'# save model: cifar10_cnn_model_best_acc_{best_epoch}-epoch.pt\\n')\n","\n","print(f'\\n\\n# Best accuracy model({best_acc * 100:.2f}%): cifar10_cnn_model_best_acc_{best_epoch}-epoch.pt\\n')"]},{"cell_type":"markdown","metadata":{"id":"FXaFzvW8a_Nl"},"source":["개선 모델 성능:\n","# 65.08%"]},{"cell_type":"markdown","metadata":{"id":"KCB2Tg-XBQFX"},"source":["개선 아이디어 설명: 파이토치의 랜덤 수평 뒤집기를 사용함. 70%의 확률로 뒤집음"]},{"cell_type":"markdown","metadata":{"id":"70OpvQ0ygpKX"},"source":["### 2) 데이터증대 + 전이학습으로 성능 높이기 (다른 pretrained model도 사용 가능)\n","pretrained model 링크: https://github.com/huyvnphan/PyTorch_CIFAR10"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DHab5Xscxd8W","executionInfo":{"status":"ok","timestamp":1699614936972,"user_tz":-540,"elapsed":756279,"user":{"displayName":"이혜림컴퓨터공학과","userId":"12232423623052772806"}},"outputId":"bac321c5-cef8-49ce-c461-5a2fae59c3c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["set vars and device done\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Train Epoch: 1 [0/50000 (0%)]\tAverage loss: 0.163048, Accuracy: 0.968750\n","Train Epoch: 1 [12800/50000 (26%)]\tAverage loss: 1.101296, Accuracy: 0.627254\n","Train Epoch: 1 [25600/50000 (51%)]\tAverage loss: 0.835268, Accuracy: 0.720932\n","Train Epoch: 1 [38400/50000 (77%)]\tAverage loss: 0.716482, Accuracy: 0.762427\n","\n","Test set: Average loss: 0.5305, Accuracy: 0.829200\n","\n","# save model: cifar10_cnn_model_best_acc_1-epoch.pt\n","\n","Train Epoch: 2 [0/50000 (0%)]\tAverage loss: 0.353486, Accuracy: 0.906250\n","Train Epoch: 2 [12800/50000 (26%)]\tAverage loss: 0.381566, Accuracy: 0.877332\n","Train Epoch: 2 [25600/50000 (51%)]\tAverage loss: 0.370761, Accuracy: 0.880143\n","Train Epoch: 2 [38400/50000 (77%)]\tAverage loss: 0.363794, Accuracy: 0.881812\n","\n","Test set: Average loss: 0.4294, Accuracy: 0.859800\n","\n","# save model: cifar10_cnn_model_best_acc_2-epoch.pt\n","\n","Train Epoch: 3 [0/50000 (0%)]\tAverage loss: 0.347496, Accuracy: 0.859375\n","Train Epoch: 3 [12800/50000 (26%)]\tAverage loss: 0.297321, Accuracy: 0.905006\n","Train Epoch: 3 [25600/50000 (51%)]\tAverage loss: 0.303990, Accuracy: 0.900210\n","Train Epoch: 3 [38400/50000 (77%)]\tAverage loss: 0.300606, Accuracy: 0.901492\n","\n","Test set: Average loss: 0.4168, Accuracy: 0.864300\n","\n","# save model: cifar10_cnn_model_best_acc_3-epoch.pt\n","\n","Train Epoch: 4 [0/50000 (0%)]\tAverage loss: 0.205655, Accuracy: 0.937500\n","Train Epoch: 4 [12800/50000 (26%)]\tAverage loss: 0.237383, Accuracy: 0.920942\n","Train Epoch: 4 [25600/50000 (51%)]\tAverage loss: 0.241104, Accuracy: 0.918797\n","Train Epoch: 4 [38400/50000 (77%)]\tAverage loss: 0.240515, Accuracy: 0.918859\n","\n","Test set: Average loss: 0.4276, Accuracy: 0.862700\n","\n","Train Epoch: 5 [0/50000 (0%)]\tAverage loss: 0.212189, Accuracy: 0.953125\n","Train Epoch: 5 [12800/50000 (26%)]\tAverage loss: 0.200695, Accuracy: 0.934546\n","Train Epoch: 5 [25600/50000 (51%)]\tAverage loss: 0.198811, Accuracy: 0.935006\n","Train Epoch: 5 [38400/50000 (77%)]\tAverage loss: 0.204638, Accuracy: 0.932144\n","\n","Test set: Average loss: 0.3646, Accuracy: 0.878100\n","\n","# save model: cifar10_cnn_model_best_acc_5-epoch.pt\n","\n","Train Epoch: 6 [0/50000 (0%)]\tAverage loss: 0.116635, Accuracy: 0.968750\n","Train Epoch: 6 [12800/50000 (26%)]\tAverage loss: 0.178515, Accuracy: 0.941620\n","Train Epoch: 6 [25600/50000 (51%)]\tAverage loss: 0.182480, Accuracy: 0.940111\n","Train Epoch: 6 [38400/50000 (77%)]\tAverage loss: 0.184580, Accuracy: 0.939346\n","\n","Test set: Average loss: 0.3080, Accuracy: 0.899400\n","\n","# save model: cifar10_cnn_model_best_acc_6-epoch.pt\n","\n","Train Epoch: 7 [0/50000 (0%)]\tAverage loss: 0.184410, Accuracy: 0.968750\n","Train Epoch: 7 [12800/50000 (26%)]\tAverage loss: 0.156925, Accuracy: 0.949238\n","Train Epoch: 7 [25600/50000 (51%)]\tAverage loss: 0.157623, Accuracy: 0.948099\n","Train Epoch: 7 [38400/50000 (77%)]\tAverage loss: 0.159020, Accuracy: 0.947535\n","\n","Test set: Average loss: 0.3298, Accuracy: 0.894700\n","\n","Train Epoch: 8 [0/50000 (0%)]\tAverage loss: 0.172919, Accuracy: 0.953125\n","Train Epoch: 8 [12800/50000 (26%)]\tAverage loss: 0.121577, Accuracy: 0.961287\n","Train Epoch: 8 [25600/50000 (51%)]\tAverage loss: 0.128573, Accuracy: 0.957762\n","Train Epoch: 8 [38400/50000 (77%)]\tAverage loss: 0.137695, Accuracy: 0.954399\n","\n","Test set: Average loss: 0.3004, Accuracy: 0.909500\n","\n","# save model: cifar10_cnn_model_best_acc_8-epoch.pt\n","\n","Train Epoch: 9 [0/50000 (0%)]\tAverage loss: 0.124376, Accuracy: 0.968750\n","Train Epoch: 9 [12800/50000 (26%)]\tAverage loss: 0.117393, Accuracy: 0.960277\n","Train Epoch: 9 [25600/50000 (51%)]\tAverage loss: 0.123068, Accuracy: 0.958619\n","Train Epoch: 9 [38400/50000 (77%)]\tAverage loss: 0.123053, Accuracy: 0.958897\n","\n","Test set: Average loss: 0.3056, Accuracy: 0.905100\n","\n","Train Epoch: 10 [0/50000 (0%)]\tAverage loss: 0.056431, Accuracy: 0.968750\n","Train Epoch: 10 [12800/50000 (26%)]\tAverage loss: 0.109595, Accuracy: 0.963153\n","Train Epoch: 10 [25600/50000 (51%)]\tAverage loss: 0.107469, Accuracy: 0.964308\n","Train Epoch: 10 [38400/50000 (77%)]\tAverage loss: 0.110386, Accuracy: 0.963394\n","\n","Test set: Average loss: 0.3317, Accuracy: 0.904600\n","\n","\n","\n","# Best accuracy model(90.95%): cifar10_cnn_model_best_acc_8-epoch.pt\n","\n"]}],"source":["batch_size = 64  # 학습 배치 크기\n","test_batch_size = 1000  # 테스트 배치 크기 (학습 과정을 제외하므로 더 큰 배치 사용 가능)\n","max_epochs = 10  # 학습 데이터셋 총 훈련 횟수\n","lr = 0.01  # 학습률\n","momentum = 0.5  # SGD에 사용할 모멘텀 설정 (파라미터 업데이트 시 관성 효과 사용)\n","log_interval = 200  # interval 때마다 로그 남김\n","\n","use_cuda = torch.cuda.is_available()  # GPU cuda 사용 여부 확인\n","\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")  # GPU cuda 사용하거나 없다면 CPU 사용\n","\n","kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}  # num_workers: data loading할 프로세스 수, pin_memory: 고정된 메모리 영역 사용\n","\n","print(\"set vars and device done\")\n","\n","train_transform = transforms.Compose([\n","                transforms.RandomHorizontalFlip(0.7), # 랜덤으로 수평 반전 (70% 확률로)\n","                                      ## augmentation 추가 가능\n","                 transforms.ToTensor(),  # numpy array -> tensor 변환\n","\n","                ## --------------- 추가 -----------------\n","                 transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616))])  # 입력값 정규화 (일반적으로는 학습 데이터셋의 평균, 표준편차 사용)\n","                 ## --------------- 추가 -----------------\n","\n","val_transform = transforms.Compose([\n","                 transforms.ToTensor(),  # numpy array -> tensor 변환\n","                 ## --------------- 추가 -----------------\n","                 transforms.Normalize((0.4914, 0.4822, 0.465), (0.2471, 0.2435, 0.2616))])  # 입력값 정규화 (일반적으로는 학습 데이터셋의 평균, 표준편차 사용)\n","                 ## --------------- 추가 -----------------\n","\n","train_loader = None\n","test_loader = None\n","\n","# CIFAR-10 link: https://www.cs.toronto.edu/~kriz/cifar.html\n","# 학습용 데이터 로더 (CIFAR-10 학습 데이터셋 사용)\n","train_loader = torch.utils.data.DataLoader(\n","  datasets.CIFAR10(os.path.join(workspace_path, 'data'), train=True, download=True,\n","                   transform=train_transform),\n","    batch_size = batch_size, shuffle=True, drop_last=True, **kwargs)  # drop_last: 마지막 미니배치 크기가 batch_size 이하면 drop\n","\n","# 테스트용 데이터 로더 (CIFAR-10 테스트 데이터셋 사용)\n","test_loader = torch.utils.data.DataLoader(\n","        datasets.CIFAR10(os.path.join(workspace_path, 'data'), train=False, download=True,\n","                         transform=val_transform),\n","    batch_size=test_batch_size, shuffle=False, **kwargs)\n","\n","## --------------- 추가 -----------------\n","from cifar10_models.densenet import densenet121\n","model = densenet121(pretrained=True).to(device)  # VGG13 model 로드\n","## --------------- 추가 -----------------\n","\n","optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)  # 최적화 알고리즘 정의 (SGD 사용)\n","criterion = nn.CrossEntropyLoss()  # 손실 함수 정의 (CrossEntropy 사용)\n","\n","best_acc = 0\n","best_epoch = 0\n","for epoch in range(1, max_epochs+1):\n","    train_loss, train_acc = train(log_interval, model, device, train_loader, optimizer, epoch)\n","    test_loss, test_acc = test(log_interval, model, device, test_loader)\n","\n","    # 테스트에서 best accuracy 달성하면 모델 저장\n","    if test_acc > best_acc:\n","        best_acc = test_acc\n","        best_epoch = epoch\n","        torch.save(model, os.path.join(workspace_path, f'cifar10_cnn_model_best_acc_{best_epoch}-epoch.pt'))\n","        print(f'# save model: cifar10_cnn_model_best_acc_{best_epoch}-epoch.pt\\n')\n","\n","print(f'\\n\\n# Best accuracy model({best_acc * 100:.2f}%): cifar10_cnn_model_best_acc_{best_epoch}-epoch.pt\\n')"]},{"cell_type":"markdown","metadata":{"id":"0GvAdfwEhCP_"},"source":["개선 모델 성능:\n","# 90.95%"]},{"cell_type":"markdown","metadata":{"id":"PnD6Kax_hEEK"},"source":["개선 아이디어 설명: github 링크에서 보았을 때, densenet121의 성능이 높은 편이여서 사용함"]},{"cell_type":"markdown","metadata":{"id":"YyFJdO0BhtCs"},"source":["### 3) 데이터증대 + 전이학습 + 추가 아이디어로 성능 높이기 (학습 과정 출력 포함)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1534422,"status":"ok","timestamp":1699616471370,"user":{"displayName":"이혜림컴퓨터공학과","userId":"12232423623052772806"},"user_tz":-540},"id":"wOjDslkLZa0g","outputId":"e3b01083-fc9b-4383-e5fe-8b62ee9fb05a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Train Epoch: 1 [0/50000 (0%)]\tAverage loss: 0.217859, Accuracy: 0.953125\n","Train Epoch: 1 [12800/50000 (26%)]\tAverage loss: 1.192889, Accuracy: 0.597404\n","Train Epoch: 1 [25600/50000 (51%)]\tAverage loss: 0.880278, Accuracy: 0.707372\n","Train Epoch: 1 [38400/50000 (77%)]\tAverage loss: 0.748332, Accuracy: 0.753536\n","\n","Test set: Average loss: 0.5726, Accuracy: 0.809900\n","\n","# save model: cifar10_cnn_model_best_acc_1-epoch.pt\n","\n","Train Epoch: 2 [0/50000 (0%)]\tAverage loss: 0.271912, Accuracy: 0.921875\n","Train Epoch: 2 [12800/50000 (26%)]\tAverage loss: 0.373979, Accuracy: 0.879742\n","Train Epoch: 2 [25600/50000 (51%)]\tAverage loss: 0.375861, Accuracy: 0.878390\n","Train Epoch: 2 [38400/50000 (77%)]\tAverage loss: 0.367760, Accuracy: 0.881318\n","\n","Test set: Average loss: 0.4215, Accuracy: 0.863600\n","\n","# save model: cifar10_cnn_model_best_acc_2-epoch.pt\n","\n","Train Epoch: 3 [0/50000 (0%)]\tAverage loss: 0.368590, Accuracy: 0.843750\n","Train Epoch: 3 [12800/50000 (26%)]\tAverage loss: 0.285199, Accuracy: 0.905162\n","Train Epoch: 3 [25600/50000 (51%)]\tAverage loss: 0.286107, Accuracy: 0.906016\n","Train Epoch: 3 [38400/50000 (77%)]\tAverage loss: 0.290278, Accuracy: 0.904170\n","\n","Test set: Average loss: 0.3949, Accuracy: 0.867100\n","\n","# save model: cifar10_cnn_model_best_acc_3-epoch.pt\n","\n","Train Epoch: 4 [0/50000 (0%)]\tAverage loss: 0.165323, Accuracy: 0.953125\n","Train Epoch: 4 [12800/50000 (26%)]\tAverage loss: 0.240460, Accuracy: 0.918843\n","Train Epoch: 4 [25600/50000 (51%)]\tAverage loss: 0.247325, Accuracy: 0.917784\n","Train Epoch: 4 [38400/50000 (77%)]\tAverage loss: 0.244118, Accuracy: 0.919873\n","\n","Test set: Average loss: 0.3419, Accuracy: 0.886900\n","\n","# save model: cifar10_cnn_model_best_acc_4-epoch.pt\n","\n","Train Epoch: 5 [0/50000 (0%)]\tAverage loss: 0.212021, Accuracy: 0.906250\n","Train Epoch: 5 [12800/50000 (26%)]\tAverage loss: 0.192590, Accuracy: 0.938200\n","Train Epoch: 5 [25600/50000 (51%)]\tAverage loss: 0.197947, Accuracy: 0.935747\n","Train Epoch: 5 [38400/50000 (77%)]\tAverage loss: 0.203520, Accuracy: 0.933418\n","\n","Test set: Average loss: 0.3973, Accuracy: 0.872900\n","\n","Train Epoch: 6 [0/50000 (0%)]\tAverage loss: 0.179933, Accuracy: 0.906250\n","Train Epoch: 6 [12800/50000 (26%)]\tAverage loss: 0.177969, Accuracy: 0.942009\n","Train Epoch: 6 [25600/50000 (51%)]\tAverage loss: 0.180597, Accuracy: 0.941786\n","Train Epoch: 6 [38400/50000 (77%)]\tAverage loss: 0.181170, Accuracy: 0.941114\n","\n","Test set: Average loss: 0.3240, Accuracy: 0.897400\n","\n","# save model: cifar10_cnn_model_best_acc_6-epoch.pt\n","\n","Train Epoch: 7 [0/50000 (0%)]\tAverage loss: 0.089091, Accuracy: 0.968750\n","Train Epoch: 7 [12800/50000 (26%)]\tAverage loss: 0.151421, Accuracy: 0.949238\n","Train Epoch: 7 [25600/50000 (51%)]\tAverage loss: 0.150555, Accuracy: 0.950242\n","Train Epoch: 7 [38400/50000 (77%)]\tAverage loss: 0.153930, Accuracy: 0.948939\n","\n","Test set: Average loss: 0.3502, Accuracy: 0.892500\n","\n","Train Epoch: 8 [0/50000 (0%)]\tAverage loss: 0.048403, Accuracy: 0.984375\n","Train Epoch: 8 [12800/50000 (26%)]\tAverage loss: 0.128041, Accuracy: 0.958411\n","Train Epoch: 8 [25600/50000 (51%)]\tAverage loss: 0.134996, Accuracy: 0.956203\n","Train Epoch: 8 [38400/50000 (77%)]\tAverage loss: 0.138797, Accuracy: 0.955309\n","\n","Test set: Average loss: 0.3360, Accuracy: 0.895600\n","\n","Train Epoch: 9 [0/50000 (0%)]\tAverage loss: 0.111034, Accuracy: 0.968750\n","Train Epoch: 9 [12800/50000 (26%)]\tAverage loss: 0.121864, Accuracy: 0.961054\n","Train Epoch: 9 [25600/50000 (51%)]\tAverage loss: 0.121045, Accuracy: 0.961152\n","Train Epoch: 9 [38400/50000 (77%)]\tAverage loss: 0.121816, Accuracy: 0.960067\n","\n","Test set: Average loss: 0.3458, Accuracy: 0.895300\n","\n","Train Epoch: 10 [0/50000 (0%)]\tAverage loss: 0.027359, Accuracy: 1.000000\n","Train Epoch: 10 [12800/50000 (26%)]\tAverage loss: 0.096116, Accuracy: 0.969683\n","Train Epoch: 10 [25600/50000 (51%)]\tAverage loss: 0.105814, Accuracy: 0.966061\n","Train Epoch: 10 [38400/50000 (77%)]\tAverage loss: 0.111298, Accuracy: 0.964460\n","\n","Test set: Average loss: 0.2944, Accuracy: 0.906700\n","\n","# save model: cifar10_cnn_model_best_acc_10-epoch.pt\n","\n","Train Epoch: 11 [0/50000 (0%)]\tAverage loss: 0.065167, Accuracy: 0.968750\n","Train Epoch: 11 [12800/50000 (26%)]\tAverage loss: 0.087147, Accuracy: 0.972637\n","Train Epoch: 11 [25600/50000 (51%)]\tAverage loss: 0.093918, Accuracy: 0.969880\n","Train Epoch: 11 [38400/50000 (77%)]\tAverage loss: 0.098702, Accuracy: 0.967632\n","\n","Test set: Average loss: 0.3356, Accuracy: 0.899400\n","\n","Train Epoch: 12 [0/50000 (0%)]\tAverage loss: 0.029521, Accuracy: 0.984375\n","Train Epoch: 12 [12800/50000 (26%)]\tAverage loss: 0.089394, Accuracy: 0.970849\n","Train Epoch: 12 [25600/50000 (51%)]\tAverage loss: 0.090313, Accuracy: 0.970231\n","Train Epoch: 12 [38400/50000 (77%)]\tAverage loss: 0.092395, Accuracy: 0.969920\n","\n","Test set: Average loss: 0.3024, Accuracy: 0.912800\n","\n","# save model: cifar10_cnn_model_best_acc_12-epoch.pt\n","\n","Train Epoch: 13 [0/50000 (0%)]\tAverage loss: 0.183466, Accuracy: 0.953125\n","Train Epoch: 13 [12800/50000 (26%)]\tAverage loss: 0.078971, Accuracy: 0.975280\n","Train Epoch: 13 [25600/50000 (51%)]\tAverage loss: 0.080617, Accuracy: 0.973543\n","Train Epoch: 13 [38400/50000 (77%)]\tAverage loss: 0.082613, Accuracy: 0.972832\n","\n","Test set: Average loss: 0.3462, Accuracy: 0.897300\n","\n","Train Epoch: 14 [0/50000 (0%)]\tAverage loss: 0.066753, Accuracy: 0.984375\n","Train Epoch: 14 [12800/50000 (26%)]\tAverage loss: 0.063733, Accuracy: 0.980255\n","Train Epoch: 14 [25600/50000 (51%)]\tAverage loss: 0.069697, Accuracy: 0.978180\n","Train Epoch: 14 [38400/50000 (77%)]\tAverage loss: 0.072804, Accuracy: 0.977017\n","\n","Test set: Average loss: 0.3538, Accuracy: 0.899400\n","\n","Train Epoch: 15 [0/50000 (0%)]\tAverage loss: 0.022049, Accuracy: 1.000000\n","Train Epoch: 15 [12800/50000 (26%)]\tAverage loss: 0.057480, Accuracy: 0.982587\n","Train Epoch: 15 [25600/50000 (51%)]\tAverage loss: 0.059848, Accuracy: 0.981219\n","Train Epoch: 15 [38400/50000 (77%)]\tAverage loss: 0.061525, Accuracy: 0.980579\n","\n","Test set: Average loss: 0.3574, Accuracy: 0.903800\n","\n","Train Epoch: 16 [0/50000 (0%)]\tAverage loss: 0.062459, Accuracy: 0.984375\n","Train Epoch: 16 [12800/50000 (26%)]\tAverage loss: 0.050010, Accuracy: 0.984220\n","Train Epoch: 16 [25600/50000 (51%)]\tAverage loss: 0.056449, Accuracy: 0.982271\n","Train Epoch: 16 [38400/50000 (77%)]\tAverage loss: 0.061365, Accuracy: 0.980605\n","\n","Test set: Average loss: 0.3270, Accuracy: 0.909900\n","\n","Train Epoch: 17 [0/50000 (0%)]\tAverage loss: 0.039771, Accuracy: 1.000000\n","Train Epoch: 17 [12800/50000 (26%)]\tAverage loss: 0.063801, Accuracy: 0.979866\n","Train Epoch: 17 [25600/50000 (51%)]\tAverage loss: 0.062868, Accuracy: 0.980284\n","Train Epoch: 17 [38400/50000 (77%)]\tAverage loss: 0.065327, Accuracy: 0.979175\n","\n","Test set: Average loss: 0.3486, Accuracy: 0.904600\n","\n","Train Epoch: 18 [0/50000 (0%)]\tAverage loss: 0.009596, Accuracy: 1.000000\n","Train Epoch: 18 [12800/50000 (26%)]\tAverage loss: 0.048349, Accuracy: 0.984530\n","Train Epoch: 18 [25600/50000 (51%)]\tAverage loss: 0.058527, Accuracy: 0.981336\n","Train Epoch: 18 [38400/50000 (77%)]\tAverage loss: 0.058229, Accuracy: 0.981255\n","\n","Test set: Average loss: 0.3242, Accuracy: 0.913100\n","\n","# save model: cifar10_cnn_model_best_acc_18-epoch.pt\n","\n","Train Epoch: 19 [0/50000 (0%)]\tAverage loss: 0.114829, Accuracy: 0.937500\n","Train Epoch: 19 [12800/50000 (26%)]\tAverage loss: 0.051874, Accuracy: 0.984841\n","Train Epoch: 19 [25600/50000 (51%)]\tAverage loss: 0.052276, Accuracy: 0.983713\n","Train Epoch: 19 [38400/50000 (77%)]\tAverage loss: 0.053096, Accuracy: 0.983075\n","\n","Test set: Average loss: 0.3410, Accuracy: 0.910400\n","\n","Train Epoch: 20 [0/50000 (0%)]\tAverage loss: 0.022040, Accuracy: 1.000000\n","Train Epoch: 20 [12800/50000 (26%)]\tAverage loss: 0.042209, Accuracy: 0.986241\n","Train Epoch: 20 [25600/50000 (51%)]\tAverage loss: 0.042783, Accuracy: 0.985817\n","Train Epoch: 20 [38400/50000 (77%)]\tAverage loss: 0.046246, Accuracy: 0.985207\n","\n","Test set: Average loss: 0.3389, Accuracy: 0.909600\n","\n","\n","\n","# Best accuracy model(91.31%): cifar10_cnn_model_best_acc_18-epoch.pt\n","\n"]}],"source":["\n","## --------------- 추가 -----------------\n","max_epochs = 20  # 학습 데이터셋 총 훈련 횟수 증가\n","## --------------- 추가 -----------------\n","momentum = 0.5\n","lr = 0.01\n","\n","train_transform = transforms.Compose([\n","                transforms.RandomHorizontalFlip(0.7), # 랜덤으로 수평 반전 (70% 확률로)\n","                                      ## augmentation 추가 가능\n","                 transforms.ToTensor(),  # numpy array -> tensor 변환\n","                 transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616))])  # 입력값 정규화 (일반적으로는 학습 데이터셋의 평균, 표준편차 사용)\n","\n","val_transform = transforms.Compose([\n","                 transforms.ToTensor(),  # numpy array -> tensor 변환\n","                 transforms.Normalize((0.4914, 0.4822, 0.465), (0.2471, 0.2435, 0.2616))])  # 입력값 정규화 (일반적으로는 학습 데이터셋의 평균, 표준편차 사용)\n","\n","train_loader = None\n","test_loader = None\n","\n","# CIFAR-10 link: https://www.cs.toronto.edu/~kriz/cifar.html\n","# 학습용 데이터 로더 (CIFAR-10 학습 데이터셋 사용)\n","train_loader = torch.utils.data.DataLoader(\n","  datasets.CIFAR10(os.path.join(workspace_path, 'data'), train=True, download=True,\n","                   transform=train_transform),\n","    batch_size = batch_size, shuffle=True, drop_last=True, **kwargs)  # drop_last: 마지막 미니배치 크기가 batch_size 이하면 drop\n","\n","# 테스트용 데이터 로더 (CIFAR-10 테스트 데이터셋 사용)\n","test_loader = torch.utils.data.DataLoader(\n","        datasets.CIFAR10(os.path.join(workspace_path, 'data'), train=False, download=True,\n","                         transform=val_transform),\n","    batch_size=test_batch_size, shuffle=False, **kwargs)\n","\n","from cifar10_models.densenet import densenet121\n","model = densenet121(pretrained=True).to(device)  # VGG13 model 로드\n","optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)  # 최적화 알고리즘 정의 (SGD 사용)\n","criterion = nn.CrossEntropyLoss()  # 손실 함수 정의 (CrossEntropy 사용)\n","\n","best_acc = 0\n","best_epoch = 0\n","for epoch in range(1, max_epochs+1):\n","    train_loss, train_acc = train(log_interval, model, device, train_loader, optimizer, epoch)\n","    test_loss, test_acc = test(log_interval, model, device, test_loader)\n","\n","    # 테스트에서 best accuracy 달성하면 모델 저장\n","    if test_acc > best_acc:\n","        best_acc = test_acc\n","        best_epoch = epoch\n","        torch.save(model, os.path.join(workspace_path, f'cifar10_cnn_model_best_acc_{best_epoch}-epoch.pt'))\n","        print(f'# save model: cifar10_cnn_model_best_acc_{best_epoch}-epoch.pt\\n')\n","\n","print(f'\\n\\n# Best accuracy model({best_acc * 100:.2f}%): cifar10_cnn_model_best_acc_{best_epoch}-epoch.pt\\n')"]},{"cell_type":"markdown","metadata":{"id":"OX-rCd-Lh3Ij"},"source":["개선 모델 성능:\n","# 91.31%"]},{"cell_type":"markdown","metadata":{"id":"0zHwNIdLh4Q5"},"source":["개선 아이디어 설명: epoch 수를 10에서 20으로 증가함. 많이 반복하면 더 좋은 결과가 나올 것이라고 예상했기 때문"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"12_cf0IfUKQlNYaQqOq30oNyDV1sp7F3f","timestamp":1699506366888},{"file_id":"1d8rScQLO9Ndv8LEXZsB4RlG1tC1SQh2Z","timestamp":1617804842085}],"gpuType":"T4"},"hide_input":false,"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":0}